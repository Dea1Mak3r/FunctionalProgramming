# Отчёт о проделанной работе

## Введение

В рамках данного проекта были решены пять алгоритмических задач с сайта LeetCode, каждая из которых демонстрирует различные подходы к оптимизации алгоритмов. Все решения были реализованы на языке Python и оптимизированы как по времени выполнения, так и по использованию памяти. В процессе работы применялись методы динамического программирования, жадные алгоритмы и математические формулы для достижения оптимальной производительности.

## Решённые задачи

### Задача №1 - Climbing Stairs

Первая задача, Climbing Stairs, представляет собой классическую задачу динамического программирования. Необходимо было найти количество различных способов подняться на лестницу из n ступенек, где на каждом шагу можно сделать либо один, либо два шага. 
Для достижения ступеньки n можно прийти либо со ступеньки n-1 (сделав шаг в 1), либо со ступеньки n-2 (сделав шаг в 2). Это наблюдение приводит к рекуррентному соотношению dp[i] = dp[i-1] + dp[i-2].

Решение было реализовано итеративно с использованием техники скользящего окна. Вместо хранения всего массива dp[0..n], который потребовал бы O(n) памяти, используются только две переменные: prev и curr, что снижает пространственную сложность до O(1). Временная сложность при этом остаётся линейной O(n). Для наглядности, если n = 2, результат равен 2 (способы: 1+1 или 2), для n = 3 результат равен 3 (1+1+1, 1+2, 2+1), а для n = 4 получается 5 способов.

### Задача №2 - Jump Game 2

Вторая задача, Jump Game II, требовала найти минимальное количество прыжков для достижения последнего индекса массива, где каждый элемент указывает максимальную длину прыжка из этой позиции. Изначально рассматривался подход динамического программирования с квадратичной сложностью O(n²), но был выбран жадный алгоритм с BFS-подобным подходом, который работает за O(n) времени и O(1) памяти.

Алгоритм работает по принципу уровней достижимости: на каждом уровне мы определяем все позиции, достижимые с текущим количеством прыжков, находим самую дальнюю позицию, достижимую из всех позиций текущего уровня, и увеличиваем счётчик прыжков. Например, для массива [2, 3, 1, 1, 4] алгоритм определяет, что с нуля прыжков доступна позиция 0, с одним прыжком можно достичь позиций 1 и 2 (farthest = 4), а со вторым прыжком достигается цель. Жадный выбор здесь корректен, так как выбор позиции с максимальной дальностью гарантирует минимальное количество прыжков.

### Задача №3 - Pascal’s Triangle 2

Третья задача связана с получением строки треугольника Паскаля. Треугольник Паскаля — это математическая структура, где каждый элемент представляет биномиальный коэффициент C(n, k) = n! / (k! * (n-k)!). Хотя можно было построить полный треугольник за O(n²) времени и памяти, было выбрано решение с использованием рекуррентной формулы C(n, k) = C(n, k-1) * (n - k + 1) / k, которое вычисляет все элементы строки за O(n) времени.

Решение начинается с установки первого элемента равным 1 (так как C(n, 0) = 1), после чего каждый последующий элемент вычисляется на основе предыдущего. Это позволяет избежать вычисления факториалов и работает эффективно даже для rowIndex = 33.

### Задача №4 - Best time to buy and sell stock 1

Четвёртая и пятая задачи посвящены максимизации прибыли от покупки и продажи акций. В четвёртой задаче разрешена только одна транзакция, что делает её более сложной, чем пятая. Решение использует жадный алгоритм, который отслеживает минимальную цену покупки и вычисляет максимальную прибыль от продажи в каждый день. Ключевое наблюдение: для любой позиции продажи j оптимальная позиция покупки — это индекс с минимальной ценой до j.

Для массива цен [7, 1, 5, 3, 6, 4] алгоритм проходит по всем дням, обновляя минимальную цену (min_price = 1 в день 1) и вычисляя потенциальную прибыль. Максимальная прибыль достигается при продаже в день 4 (цена = 6) после покупки в день 1 (цена = 1), что даёт прибыль 5. При этом полный перебор всех пар (i, j) потребовал бы O(n²) операций, тогда как жадный алгоритм решает задачу за O(n).

### Задача №5 - Best time to buy and sell stock 2

Пятая задача отличается тем, что разрешено совершать множество транзакций. Это упрощает решение: достаточно собрать все восходящие тренды, то есть суммировать все положительные разности между соседними днями. Если цена растёт от дня i к дню i+1, мы покупаем в день i и продаём в день i+1, получая прибыль от этого роста.

Заметим, что если цена растёт несколько дней подряд (например, 1 → 2 → 3), то сумма прибылей от соседних дней (1→2 и 2→3) равна прибыли от первой до последней транзакции (1→3). Это означает, что сбор всех восходящих трендов эквивалентен оптимальной стратегии. Для массива [7, 1, 5, 3, 6, 4] алгоритм находит восходящие тренды 1→5 (прибыль 4) и 3→6 (прибыль 3), что в сумме даёт общую прибыль 7.

## Методология решения задач

При работе над задачами применялся систематический подход, который можно разбить на несколько этапов. Первый этап — это тщательный анализ проблемы, включающий понимание постановки задачи, определение входных и выходных данных, а также выявление всех ограничений. Например, важно было понимать, можно ли совершать множественные транзакции, есть ли ограничения на количество прыжков или шагов.

Второй этап заключается в выявлении паттернов и поиске повторяющихся подзадач. Это особенно важно для задач на динамическое программирование, где нужно определить рекуррентное соотношение и проанализировать оптимальную подструктуру. В случае с задачей Climbing Stairs сразу становится очевидным, что количество способов достичь ступеньки n зависит от количества способов достичь предыдущих ступенек.

Третий этап — выбор алгоритма. Для каждой задачи рассматривались различные подходы: динамическое программирование, жадные алгоритмы, полный перебор, математические формулы. Например, для задачи Jump Game II можно было использовать DP с квадратичной сложностью, но жадный алгоритм оказался более эффективным. Важно было не только найти работающее решение, но и выбрать наиболее оптимальное по времени и памяти.

Четвёртый этап — реализация оптимизаций. Здесь применялись техники минимизации использования памяти, такие как скользящее окно, когда вместо хранения всего массива используются только необходимые переменные. Также важно было избежать повторных вычислений, что особенно критично для рекурсивных алгоритмов без мемоизации.

Пятый этап включал анализ сложности с использованием Big O нотации. Это необходимо для понимания масштабируемости решения и сравнения с альтернативными подходами. Например, разница между O(n) и O(n²) для n = 10⁵ составляет 10⁵ операций против 10¹⁰ операций, что в сто тысяч раз больше.

Шестой этап — обработка граничных случаев. Необходимо проверять входные данные на пустоту, минимальные и максимальные значения, чтобы алгоритм работал корректно во всех ситуациях.

## Динамическое программирование

Динамическое программирование — это мощный метод решения задач оптимизации, основанный на разбиении задачи на более простые подзадачи. Ключевая идея заключается в том, что оптимальное решение основной задачи содержит оптимальные решения подзадач. Это свойство называется оптимальной подструктурой.

В задаче Climbing Stairs оптимальная подструктура проявляется в том, что количество способов достичь ступеньки n равно сумме способов достичь ступенек n-1 и n-2. Например: если мы на ступеньке n-1, нам нужен один шаг, если на n-2 — два шага. Другим важным свойством является наличие перекрывающихся подзадач, когда одна и та же подзадача решается многократно при рекурсивном подходе.

Существуют два основных подхода к динамическому программированию. Первый — мемоизация (Top-Down), где решение строится рекурсивно с сохранением результатов в кэше. Этот подход интуитивно понятен и решает только необходимые подзадачи, но имеет недостатки: накладные расходы на рекурсивные вызовы и риск переполнения стека для больших значений n.

Второй подход — табуляция (Bottom-Up), где решение строится итеративно, заполняя таблицу решений от базовых случаев к конечной цели. Этот подход не имеет накладных расходов на рекурсию и позволяет оптимизировать использование памяти. В задаче Climbing Stairs был выбран именно этот подход, что позволило снизить пространственную сложность до O(1), используя только две переменные вместо массива размера n.

Динамическое программирование применимо, когда задача может быть разбита на подзадачи, подзадачи перекрываются, существует оптимальная подструктура и решения подзадач могут быть сохранены и переиспользованы. Типичные признаки задач на DP включают фразы "найти количество способов" или "найти минимальное/максимальное значение", а также задачи о последовательностях и подмножествах.

## Big O нотация и анализ сложности

Big O нотация — это математический инструмент для описания асимптотического поведения функций при стремлении аргумента к бесконечности. В информатике она используется для характеристики временной и пространственной сложности алгоритмов, позволяя понять, как производительность алгоритма изменяется с ростом размера входных данных.

Формально, функция f(n) имеет порядок O(g(n)), если существуют положительные константы c и n₀ такие, что f(n) ≤ c · g(n) для всех n ≥ n₀. Это означает, что f(n) растёт не быстрее, чем g(n) с точностью до константного множителя. Важно понимать, что Big O описывает верхнюю границу производительности в худшем случае.

Основные классы сложности, с которыми мы сталкивались в проекте, включают O(1) — константное время, когда выполнение не зависит от размера входных данных, O(log n) — логарифмическое время, характерное для бинарного поиска, O(n) — линейное время, которое имеет большинство решённых задач, O(n log n) — линеарифмическое время для эффективных алгоритмов сортировки, O(n²) — квадратичное время для полного перебора пар, и O(2ⁿ) — экспоненциальное время для рекурсивных алгоритмов без мемоизации.

В анализе сложности важно игнорировать константы, так как O(2n) = O(n), а также учитывать доминирующий член, поэтому O(n² + n) = O(n²). При суммировании последовательных операций сложности складываются, а при вложенных циклах — перемножаются.

Практическое значение Big O огромно. Для массива размера n = 10⁵ алгоритм O(n) выполнит 10⁵ операций, а алгоритм O(n²) — 10¹⁰ операций, что в сто тысяч раз больше. Это показывает, почему оптимизация важна: улучшение алгоритма с O(n²) до O(n) в четвёртой задаче даёт выигрыш в производительности в тысячи раз для больших массивов.

Все решённые задачи имеют временную сложность O(n) или O(rowIndex), что является оптимальным для задач данного типа. Пространственная сложность большинства задач составляет O(1), что достигается использованием техники скользящего окна и отказом от хранения избыточных структур данных.

## Мемоизация в рекурсии

Мемоизация — это техника оптимизации, при которой результаты выполнения функции сохраняются в кэше и переиспользуются при повторных вызовах с теми же аргументами. Это позволяет избежать повторных вычислений в рекурсивных алгоритмах и значительно ускорить их работу.

Принцип работы мемоизации прост: перед вычислением функции проверяется, есть ли результат в кэше. Если результат есть, он возвращается без вычислений. Если результата нет, функция вычисляется, результат сохраняется в кэше и возвращается. Это особенно эффективно для задач с перекрывающимися подзадачами, где одни и те же вычисления выполняются многократно.

Классический пример — вычисление чисел Фибоначчи. Рекурсивное решение без мемоизации имеет экспоненциальную сложность O(2ⁿ), так как fib(n-2) вычисляется дважды при каждом вызове. Дерево вызовов для fib(5) показывает, что некоторые значения вычисляются многократно, что крайне неэффективно.

С мемоизацией каждое значение вычисляется только один раз, что снижает временную сложность до O(n). Пространственная сложность при этом составляет O(n) для хранения результатов. В Python мемоизацию можно реализовать с помощью декоратора @lru_cache из модуля functools или создать собственный декоратор, который хранит результаты в словаре.

Для задачи Climbing Stairs можно было использовать рекурсивное решение с мемоизацией, но было выбрано итеративное решение (табуляция) по нескольким причинам. Во-первых, оно не требует дополнительной памяти для кэша. Во-вторых, нет накладных расходов на рекурсивные вызовы. В-третьих, можно оптимизировать память до O(1), используя только две переменные вместо массива.

Мемоизация полезна, когда функция вызывается многократно с одинаковыми аргументами, вычисления дорогие, результат детерминирован и в алгоритме есть перекрывающиеся подзадачи. Однако её не следует использовать, когда функция вызывается редко, вычисления быстрые, нет перекрывающихся подзадач или память ограничена.

Сравнивая мемоизацию (Top-Down) и табуляцию (Bottom-Up), можно сказать, что мемоизация лучше, когда нужно решить только часть подзадач, а табуляция предпочтительнее, когда нужны все подзадачи или требуется оптимизация памяти. В нашем проекте для первой задачи был выбран итеративный подход именно для оптимизации памяти до O(1).

## Практические выводы и заключение

Работа над проектом продемонстрировала важность понимания различных подходов к решению алгоритмических задач и умения выбирать оптимальный метод в зависимости от требований. Динамическое программирование оказалось эффективным для задач с перекрывающимися подзадачами и оптимальной подструктурой, жадные алгоритмы — для задач, где локально оптимальный выбор приводит к глобально оптимальному решению, а математические формулы — когда можно вычислить результат напрямую без построения промежуточных структур.

Все решения оптимизированы по времени до O(n) или O(rowIndex), что является оптимальным для данных типов задач. Пространственная сложность большинства решений составляет O(1), что достигается использованием техники скользящего окна и отказом от хранения избыточных данных. Это особенно важно для работы с большими массивами, где разница между O(n²) и O(n) может составлять тысячи и даже миллионы операций.

Важным аспектом работы стала необходимость анализа альтернативных подходов и понимания компромиссов между простотой реализации, временной сложностью и использованием памяти. Например, в задаче Jump Game II жадный алгоритм оказался не только более эффективным, но и более простым в реализации по сравнению с динамическим программированием. А в задаче Pascal's Triangle использование математической формулы позволило достичь линейной сложности вместо квадратичной.

Применение Big O нотации помогло объективно оценить производительность алгоритмов и выбрать оптимальное решение. Понимание того, что O(n) алгоритм может обработать в 10 раз больше данных за 10 раз больше времени, в то время как O(n²) алгоритм потребует в 100 раз больше времени, критически важно для работы с реальными системами.

Мемоизация показала, как можно оптимизировать рекурсивные алгоритмы, но также продемонстрировала важность выбора между различными подходами. В некоторых случаях итеративное решение может быть более эффективным, чем рекурсивное с мемоизацией, особенно когда можно оптимизировать память до O(1).

Решённые задачи имеют практическое применение в реальных системах: задачи о подъёме по лестнице связаны с комбинаторикой и вероятностями, задачи о прыжках — с графами и обходом, треугольник Паскаля используется в математике и статистике, а задачи о покупке и продаже акций имеют прямое отношение к финансовым алгоритмам и трейдингу.

Проект показал, что успешное решение алгоритмических задач требует не только знания различных техник и методов, но и умения анализировать проблему, выявлять паттерны, сравнивать альтернативы и делать обоснованный выбор. Все эти навыки критически важны для разработки эффективного и масштабируемого программного обеспечения.

## Структура проекта

Проект содержит следующие файлы:

- `Task1.py` — решение задачи Climbing Stairs (динамическое программирование)
- `Task2.py` — решение задачи Jump Game II (жадный алгоритм)
- `Task3.py` — решение задачи Pascal's Triangle Row (формула комбинаций)
- `Task4.py` — решение задачи Best Time to Buy and Sell Stock (жадный алгоритм, одна транзакция)
- `Task5.py` — решение задачи Best Time to Buy and Sell Stock II (жадный алгоритм, множественные транзакции)
- `README.md` — данный отчёт о проделанной работе

Все решения реализованы на Python 3 и оптимизированы по времени и памяти в соответствии с требованиями задач.